RocketMQ

​		RocketMQ是阿里巴巴中间件团队自研的一款高性能、高吞吐量、低延迟、高可用、高可靠（具备 金融

级稳定性）的分布式消息中间件，开源后并于2016年捐赠给Apache社区孵化，目前已经成为了 Apache顶级项

目。当前在国内被广泛的使用，包括互联网、电商、金融、企业服务等领域，包括：字 节跳动、滴滴、微众

银行等知名的互联网公司。

​		https://github.com/apache/rocketmq

##  第一部分 RocketMQ架构与实战

###  一、RocketMQ的前世今生

​		RocketMQ在阿里内部叫做Metaq（最早名为Metamorphosis，中文意思“变形记”，是作家卡夫卡 的中篇小

说代表作，可见是为了致敬Kafka）。

​		 RocketMQ是Metaq 3.0之后开源的版本。 

​		Metaq在阿里巴巴集团内部、蚂蚁金服、菜鸟等各业务中被广泛使用，接入了上万个应用系统中。 并平

稳支撑了历年的双十一大促（万亿级的消息），在性能、稳定性、可靠性等方面表现出色，在整个 阿里技术

体系和大中台战略中发挥着举足轻重的作用。

​		 Metaq最早源于Kafka，早期借鉴了Kafka很多优秀的设计。但是由于Kafka是Scale语言编写而阿里系主

要使用Java，且无法满足阿里的电商、金融业务场景，所以誓嘉（花名）团队用Java重新造轮子， 并做了大

量的改造和优化。 

​		在此之前，淘宝有一款消息中间件名为Notify，目前已经逐步被Metaq所取代。 第一代的Notify主要使用

了推模型，解决了事务消息；第二代的MetaQ主要使用了拉模型，解决了 顺序消息和海量堆积的问题。

​		相比起Kafka使用的Scale语言编写，RabbitMQ 使用Erlang语言编写，基于Java的RocketMQ开源后更容易

被广泛的研究，以及其他大厂定制开发。

![Snipaste_2021-06-26_09-57-16](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-26_09-57-16.png) 

###  二、RocketMQ使用场景

- 应用解耦

  ​		系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、 

  物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异 

  常，影响用户使用体验。

- 流量削峰填谷

  ​		应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求 

  缓存起来，分散到很长一段时间处理，这样可以大大提高系统的稳定性和用户体验。 

  ​		举例:业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量高峰配置高性能的服

  务器显然不划算，这时可以使用消息队列对峰值流量削峰

- 数据分发

  ​		通过消息队列可以让数据在多个系统之间进行流通。数据的产生方不需要关心谁来使用数据，只需 
  
  要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可

###  三、RocketMQ部署架构与实战

#### 3.1 架构角色介绍

- Producer：消息生产者，生产消息发送到broker供消费者消费；

- Consumer：消息消费者，消费生产者发送到broker的消息；

- Broker：消息中间件服务器，负责消息的暂存和传输，同时和生产者、消费者打交道；

- Name Server：架构管理者，负责管理Broker，并向生产者和消费者提供broker集群信息（包括Topic主题路由信息）；

- Topic：消息主题，区分消种类，一个生产者可以发送消息到一个或多个Topic，一个消费者可以订阅或消

  费一个或多个Topic；

- Message Queue：主题的消息队列实体，用于并发消费和并发生产消息的负载均衡，相当于Topic的分区。

  在 RocketMQ 中，所有消息队列都是持久化的，长度无限的数据结构，所谓长度无限是指队列中的每个存

  储单元都是定长，访问其中的存储单元使用**Offset**来访问，offset 为 java **long** 类型，64 位，理论上在 100 

  年内不会溢出，所以认为为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间

  来删除。也可以认为Message Queue是一个长度无限的数组，offset 就是下标。

![Snipaste_2021-06-26_16-25-47](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-26_16-25-47.png)

#### 3.2 架构角色说明

##### 3.2.1 Name Server 注册中心

> 几乎无状态，可集群部署，各结点之间无任何通讯和数据同步。Name Server启动后会监听端口，等待Broker、Producer、Consumer连接，相当于一个路由控制中心。

**注意：为什么RocketMQ不使用Zookeeper而自己开发NameServer。**

在**服务发现领域**，ZooKeeper 根本就不能算是最佳的选择。

- **注册中心是CP还是AP系统**

  ​		在分布式系统中，即使是对等部署的服务，因为请求到达的时间，硬件的状态，操作系统的调度，

  虚拟机的GC等，任何一个时间点，这些对等部署的节点状态也不可能完全一致，而流量不一致的情况

  下，只要注册中心在A承诺的时间内（例如1s内）将数据收敛到一致状态（即满足最终一致），流量将

  很快趋于统计学意义上的一致，所以注册中心以最终一致的模型设计在生产实践中完全可以接受。

- **分区容忍及可用性需求分析实践中，注册中心不能因为自身的任何原因破坏服务之间本身的可连通性，这是**

  **注册中心设计应该遵循的铁律**

  ​		在CAP的权衡中，注册中心的可用性比数据强一致性更宝贵，所以整体设计更应该偏向AP，而非CP，数

  据不一致在可接受范围，而P下舍弃A却完全违反了注册中心不能因为自身的任何原因破坏服务本身的可连通

  性的原则。

- **服务规模、容量、服务联通性**

  ​		当数据中心服务规模超过一定数量，作为注册中心的ZooKeeper性能堪忧。

  ​		在服务发现和健康监测场景下，随着服务规模的增大，无论是应用频繁发布时的服务注册带来的写请求，

  还是刷毫秒级的服务健康状态带来的写请求，还是恨不能整个数据中心的机器或者容器皆与注册中心有长连接

  带来的连接压力上，ZooKeeper很快就会力不从心，而ZooKeeper的写并不是可扩展的，不可以通过加节点

  解决水平扩展性问题。

-  **注册中心需要持久存储和事务日志么？ 需要，也不需要。**

  ​		在服务发现场景中，其最核心的数据——实时的健康的服务的地址列表，真的需要数据持久化么？不需要

  ​		在服务发现中，服务调用发起方更关注的是其要调用的服务的实时的地址列表和实时健康状态，每次发起

  调用时，并不关心要调用的服务的历史服务地址列表、过去的健康状态。

  ​		但是一个完整的生产可用的注册中心，除了服务的实时地址列表以及实时的健康状态之外，还会存储一些

  服务的元数据信息，例如服务的版本，分组，所在的数据中心，权重，鉴权策略信息，服务标签等元数据，这

  些数据需要持久化存储，并且注册中心应该提供对这些元数据的检索的能力。

-  **服务健康检查**

  ​		使用ZooKeeper作为服务注册中心时，服务的健康检测绑定在了ZooKeeper对于Session的健康监测上，

  或者说绑定在TCP长链接活性探测上了。

  ​		ZK与服务提供者机器之间的TCP长链接活性探测正常的时候，该服务就是健康的么？答案当然是否定的！

  注册中心应该提供更丰富的健康监测方案，服务的健康与否的逻辑应该开放给服务提供方自己定义，而不是一

  刀切搞成了TCP活性检测！

  ​		健康检测的一大基本设计原则就是尽可能真实的反馈服务本身的真实健康状态，否则一个不敢被服务调用

  者相信的健康状态判定结果还不如没有健康检测。

- **注册中心的容灾考虑**

  ​		如果注册中心（Registry）本身完全宕机了，服务调用链路应该受到影响么？

  ​		不应该受到影响。

  ​		服务调用（请求响应流）链路应该是弱依赖注册中心，必须仅在服务发布，机器上下线，服务扩缩容等必

  要时才依赖注册中心。

  ​	这需要注册中心仔细的设计自己提供的客户端，客户端中应该有针对注册中心服务完全不可用时做容灾的手

  段，例如设计客户端缓存数据机制就是行之有效的手段。另外，注册中心的健康检查机制也要仔细设计以便在

  这种情况不会出现诸如推空等情况的出现。

  ​		ZooKeeper的原生客户端并没有这种能力，所以利用ZooKeeper实现注册中心的时候我们一定要问自

  己，如果把ZooKeeper所有节点全干掉，你生产上的所有服务调用链路能不受任何影响么

- **你有没有ZooKeeper的专家可依靠？**

  - 难以掌握的Client/Session状态机

  - 难以承受的异常处理

    阿里巴巴是不是完全没有使用 ZooKeeper？并不是。

  ​		熟悉阿里巴巴技术体系的都知道，其实阿里巴巴维护了目前国内最大规模的ZooKeeper集群，整体规模

  有近千台的ZooKeeper服务节点。

  ​		在粗粒度分布式锁，分布式选主，主备高可用切换等不需要高TPS支持的场景下有不可替代的作用，而这

  些需求往往多集中在大数据、离线任务等相关的业务领域，因为大数据领域，讲究分割数据集，并且大部分时

  间分任务多进程/线程并行处理这些数据集，但是总是有一些点上需要将这些任务和进程统一协调，这时候就

  是ZooKeeper发挥巨大作用的用武之地。

  ​		但是在交易场景交易链路上，在主业务数据存取，大规模服务发现、大规模健康监测等方面有天然的短

  板，应该竭力避免在这些场景下引入ZooKeeper，在阿里巴巴的生产实践中，应用对ZooKeeper申请使用的

  时候要进行严格的场景、容量、SLA需求的评估。

  ​		对于ZooKeeper，大数据使用，服务发现不用。

##### 3.2.2 Broker 消息队列

> 角色分主节点和从结点，Broker Name相同Broker Id不同的为一组主从集群，Broker Id为0的结点为主结点，Broker Id大于0的结点为从结点，只有Broker Id为1的从结点可以负载读请求。Broker Name不同的为不同的主从集群，每个Topic的Message Queue均匀的分布在各主从集群上。每个Broker，包括主结点与从结点，均会与Name Server集群中的每个结点建立长连接，并定时发送心跳包。心跳包中包含当前的Broker信息（IP + 端口等）以及存储的所有Topic信息。

######  Tag 标签

​		为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。

######  消息存储

- 存储介质

  - 关系型数据库DB

    ​		Apache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用JDBC的方式 来做消息持久化，通过简单的xml配置信息即可实现JDBC消息存储。由于，普通关系型数据库（如 Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。在可靠性方面，该种方 案非常依赖DB，如果一旦DB出现故障，则MQ的消息就无法落盘存储会导致线上故障

  - 文件系统

    ​		目前业界较为常用的几款产品（RocketMQ/Kafka/RabbitMQ）均采用的是消息刷盘至所部署虚拟机/物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。消息刷盘为消 息存储提供了一种高效率、高可靠性和高性能的数据持久化方式。除非部署MQ机器本身或是本地磁盘挂了，否则一般是不会出现无法持久化的故障问题。

- 消息的存储和发送

  - 消息存储

    ​		目前的高性能磁盘，**顺序写**速度可以达到600MB/s， 超过了一般网卡的传输速度。 但是磁盘随机写的速度只有大概100KB/s，和顺序写的性能相差6000倍！ 因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。 RocketMQ的消息用顺序写,保证了消息存储的速度。

  - 存储结构

    ​		RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件 是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储 的地址。每个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。![Snipaste_2021-06-29_19-49-15](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-29_19-49-15.png)

    ​		消息存储架构图中主要有下面三个跟消息存储相关的文件构成。

    1. CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移 量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为 1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件；

    2. ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行如果要遍历commitlog文件根据topic检索消息是非常低效的。 Consumer即可根据ConsumeQueue来查找待消费的消息。 其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引： 

       - 保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset 
       - 消息大小size 
       - 消息Tag的HashCode值。 

       consumeQueue文件可以看成是基于topic的commitlog索引文件，故consumeQueue文件夹的组织方式如下：

        topic/queue/file三层组织结构

       具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。

       consumequeue文件采取定长设计，每个条目共20个字节，分别为： 

       - 8字节的commitlog物理偏移量 
       - 4字节的消息长度 
       -  8字节tag hashcode 

       单个文件由30W个条目组成，可以像数组一样随机访问每一个条目每个ConsumeQueue文件大小约**5.72M**；

    3. IndexFile：IndexFile（索引文件）提供了一种**可以通过key或时间区间来查询消息**的方法。 
       - Index文件的存储位置是： $HOME/store/index/${fileName} 
       - 文件名fileName是以创建时的时间戳命名的 
       - 固定的单个IndexFile文件大小约为400M 
       - 一个IndexFile可以保存 2000W个索引 
       - IndexFile的底层存储设计为在文件系统中实现**HashMap结构**，故rocketmq的索引文件其**底层实现为hash索引**。

######  过滤消息

​		RocketMQ的消费者可以根据Tag进行消息过滤，也支持自定义属性过滤。消息过滤目前是在Broker端实现的，优点是减少了对于Consumer无用消息的网络传输，缺点是增加了Broker的负担、而且实现相对复杂。

​		RocketMQ分布式消息队列的消息过滤方式有别于其它MQ中间件，是在**Consumer端订阅消息时再做消息过滤的**。 

​		RocketMQ这么做是在于其Producer端写入消息和Consumer端订阅消息采用分离存储的机制来实现的，Consumer端订阅消息是需要通过ConsumeQueue这个消息消费的逻辑队列拿到一个索引，然后再从CommitLog里面读取真正的消息实体内容，所以说到底也是还绕不开其存储结构。 

​		其ConsumeQueue的存储结构如下，可以看到其中有8个字节存储的Message Tag的哈希值，基于Tag的消息过滤正式基于这个字段值的。

![ConsumerQueue结点结构](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-29_20-32-10.png)

​		主要支持如下2种的过滤方式 

- Tag过滤方式：Consumer端在订阅消息时除了指定Topic还可以指定TAG，如果一个消息有多 个TAG，可以用||分隔。 

  - Consumer端会将这个订阅请求构建成一个 SubscriptionData，发送一个Pull消息的请求给 Broker端。 
  - Broker端从RocketMQ的文件存储层—Store读取数据之前，会用这些数据先构建一个 MessageFilter，然后传给Store。 
  - Store从 ConsumeQueue读取到一条记录后，会用它记录的消息tag hash值去做过滤。 
  - 在服务端**只是根据hashcode进行判断，无法精确对tag原始字符串进行过滤**，在消息消费端拉取到消息后，还需要对消息的原始tag字符串进行比对，如果不同，则丢弃该消息，不进行消息消费。 

- SQL92的过滤方式： 仅对push的消费者起作用。 

  Tag方式虽然效率高，但是支持的过滤逻辑比较简单。 

  SQL表达式可以更加灵活的支持复杂过滤逻辑，这种方式的大致做法和上面的Tag过滤方式一样， 只是在Store层的具体过滤过程不太一样。

  真正的SQL expression的构建和执行由rocketmq-filter模块负责的。 每次过滤都去执行SQL表达式会影响效率，所以RocketMQ使用了BloomFilter避免了每次都去执行。 

  SQL92的表达式上下文为消息的属性。

  启用SQL92

  ```shell
  #修改broker配置文件
  vim conf/broker.conf
  #开启SQL92过滤
  enablePropertyFilter=true
  #指定配置文件重启broker
  mqbroker -n localhost:9876 -c /opt/rocket/conf/broker.conf
  ```

  RocketMQ仅定义了几种基本的语法，用户可以扩展： 

  - 数字比较： >, >=, <, <=, BETWEEN, = 

  - 字符串比较： =, <>, IN; IS NULL或者IS NOT NULL; 

  - 逻辑比较： AND, OR, NOT; 

  - Constant types are: 数字如：123, 3.1415; 字符串如：'abc'，必须是单引号引起来 NULL,特 殊常量 布尔型如：TRUE or FALSE;

    ![SQL92用法](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-12-24_11-14-28.png)

- Filter Server方式：这是一种比SQL表达式更灵活的过滤方式，允许用户自定义Java函数，根据 Java函数的逻辑对消息进行过滤。 

  要使用Filter Server，首先要在启动Broker前在配置文件里加上 filterServer-Nums=3 这样的配 置，Broker在启动的时候，就会在本机启动3个Filter Server进程。Filter Server类似一个RocketMQ的 Consumer进程，它从本机Broker获取消息，然后根据用户上传过来的Java函数进行过滤，过滤后的消 息再传给远端的Consumer。 

  这种方式会占用很多Broker机器的CPU资源，要根据实际情况谨慎使用。上传的java代码也要经过检查，不能有申请大内存、创建线程等这样的操作，否则容易造成Broker服务器宕机。

######  刷盘机制

​		RocketMQ 的所有消息都是持久化的，先写入系统PageCache，然后刷盘，可以保证内存与磁盘都有一份数

据， 访问时，直接从内存读取。消息在通过Producer写入RocketMQ的时候，有两种写磁盘方式，分布式同步刷

盘和异步刷盘。

- **同步刷盘**

  ​		同步刷盘与异步刷盘的唯一区别是异步刷盘写完 PageCache直接返回，而同步刷盘需要等待刷盘

  完成才返回， 同步刷盘流程如下：

  (1). 写入 PageCache后，线程等待，通知刷盘线程刷盘。

  (2). 刷盘线程刷盘后，唤醒前端等待线程，可能是一批线程。

  (3). 前端等待线程向用户返回成功

- **异步刷盘**

  ​		在有 RAID 卡，SAS 15000 转磁盘测试顺序写文件，速度可以达到 300M 每秒左右，而线上的网卡一般都

  为千兆 网卡，写磁盘速度明显快于数据网络入口速度，那么是否可以做到写完内存就向用户返回，由后台线

  程刷盘呢？

  1. 由于磁盘速度大于网卡速度，那么刷盘的进度肯定可以跟上消息的写入速度。

  2. 万一由于此时系统压力过大，可能堆积消息，除了写入 IO，还有读取 IO，万一出现磁盘读取落后情况， 

  会不会导致系统内存溢出，答案是否定的，原因如下：

  - 写入消息到 PageCache时，如果内存不足，则尝试丢弃干净的 PAGE，腾出内存供新消息使用，策略是LRU 方式。

  - 如果干净页不足，此时写入 PageCache会被阻塞，系统尝试刷盘部分数据，大约每次尝试 32个 PAGE , 来找出更多干净 PAGE。

  综上，内存溢出的情况不会出现。

######  同步复制和异步复制

​		如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。

- **同步复制**

  ​		同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；

  ​		在同步复制方式下，如果Master出故障，Slave上有全部的备份数据，容易恢复，但是同步复制会

  增大数据写入延迟，降低系统吞吐量。

- **异步复制**

  ​		异步复制方式是只要Master写成功即可反馈给客户端写成功状态。

  ​		在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；

- **配置**

  同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置

  成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。

  ![Broker配置参数](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\截图20210630231341.png)

- **总结**

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-30_23-17-15.png)

  ​		实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式， 尤其是SYNC_FLUSH方式，由于

  频繁地触发磁盘写动作，会明显降低性能。通常情况下，应该把Master和Save配置成ASYNC_FLUSH的

  刷盘方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台机器出故障，仍然能保证数据

  不丢，是个不错的选择。

######  动态扩缩容

- **扩容**

  ​		由于业务增长，需要对集群进行扩容的时候，可以动态增加Broker角色的机器。只增加Broker不会对原

  有的Topic产生影响，原来创建好的Topic中数据的读写依然在原来的那些Broker上进行。

  ​		集群扩容后，一是可以把新建的Topic指定到新的Broker机器上，均衡利用资源；另一种方式是通过

  updateTopic命令更改现有的Topic配置，在新加的Broker上创建新的队列。比如TestTopic是现有的一个

  Topic，因为数据量增大需要扩容，新增的一个Broker机器地址是192.168.0.1：10911，这个时候执行下面的

  命令：sh./bin/mqadmin updateTopic-b 192.168.0.1:10911 -t TestTopic -n 192.168.0.100:9876，结果是

  在新增的Broker机器上，为TestTopic新创建了8个读写队列。

- **缩容**

  ​		如果因为业务变动或者置换机器需要减少Broker，此时该如何操作呢？减少Broker要看是否有持续运行

  的Producer，当一个Topic只有一个Master Broker，停掉这个Broker后，消息的发送肯定会受到影响，需要

  在停止这个Broker前，停止发送消息。

  ​		当某个Topic有多个Master Broker，停了其中一个，这时候是否会丢失消息呢？答案和Producer使用的

  发送消息的方式有关，如果使用同步方式send（msg）发送，在DefaultMQProducer内部有个自动重试逻

  辑，其中一个Broker停了，会自动向另一个Broker发消息，不会发生丢消息现象。如果使用异步方式发送

  send（msg，callback），或者用sendOneWay方式，会丢失切换过程中的消息。因为在异步和

  sendOneWay这两种发送方式下，Producer.setRetryTimesWhenSendFailed设置不起作用，发送失败不会

  重试。DefaultMQProducer默认每30秒到NameServer请求最新的路由消息，Producer如果获取不到已停止

  的Broker下的队列信息，后续就自动不再向这些队列发送消息。

  ​		如果Producer程序能够暂停，在有一个Master和一个Slave的情况下也可以顺利切换。可以关闭

  Producer后关闭Master Broker，这个时候所有的读取都会被定向到Slave机器，消费消息不受影响。把

  Master Broker机器置换完后，基于原来的数据启动这个Master Broker，然后再启动Producer程序正常发送

  消息。

  ​		用Linux的kill pid命令就可以正确地关闭Broker，BrokerController下有个shutdown函数，这个函数被

  加到了ShutdownHook里，当用Linux的kill命令时（不能用kill-9），shutdown函数会先被执行。也可以通过

  RocketMQ提供的工具（mqshutdown broker）来关闭Broker，它们的原理是一样的





##### 3.2.3 Producer 消息生产者

> ​			结点无状态，可集群部署。Producer启动时，随机与Name Server集群中的一个结点建立长连接 ，并定期从Name 
>
> Server获取Topic路由信息，并与提供Topic服务的Broker Master结点建立长连接，且定时向Broker Master发送心跳。

######  ProducerGroup

​		同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事务消息且原始生产者在发送之后

崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。

###### 消息发送

​		是指Producer向某个Topic发送消息.。

​		生产者向消息队列里写入消息，不同的业务场景需要生产者采用不同的写入策略。比如同步发送、 异步发送、Oneway发送、延迟发送、发送事务消息等。 默认使用的是DefaultMQProducer类，发送消息要经过五个步骤： 

1）设置Producer的GroupName。 

2）设置InstanceName，当一个Jvm需要启动多个Producer的时候，通过设置不同的 InstanceName来区分，不设置的话系统使用默认名称“DEFAULT”。 

3）设置发送失败重试次数，当网络出现异常的时候，这个次数影响消息的重复投递次数。想保证不丢消息，可以设置多重试几次。 

4）设置NameServer地址

5）组装消息并发送。

 		消息发送返回状态（SendResult#SendStatus）有如下四种： 

​		FLUSH_DISK_TIMEOUT 

​		FLUSH_SLAVE_TIMEOUT 

​		SLAVE_NOT_AVAILABLE 

​		SEND_OK 

​		不同状态在不同的刷盘策略和同步策略的配置下含义是不同的： 

1. **FLUSH_DISK_TIMEOUT：**表示没有在规定时间内完成刷盘（需要Broker的刷盘策略被设置成 SYNC_FLUSH才会报这个错误）。 

2. **FLUSH_SLAVE_TIMEOUT：**表示在主备方式下，并且Broker被设置成SYNC_MASTER方式， 没有在设定时间内完成主从同步。 

3. **SLAVE_NOT_AVAILABLE：**这个状态产生的场景和FLUSH_SLAVE_TIMEOUT类似，表示在主备方式下，并且Broker被设置成SYNC_MASTER，但是没有找到被配置成Slave的Broker。 

4.  **SEND_OK：**表示发送成功，发送成功的具体含义，比如消息是否已经被存储到磁盘？消息是否被同步到了Slave上？消息在Slave上是否被写入磁盘？需要结合所配置的刷盘策略、主从策略来定。这个状态还可以简单理解为，没有发生上面列出的三个问题状态就是SEND_OK。 

   写一个高质量的生产者程序，重点在于对发送结果的处理，要充分考虑各种异常，写清对应的处理逻辑。 

   **提升写入的性能** 

   发送一条消息出去要经过三步 

   1. 客户端发送请求到服务器。 
   
   2. 服务器处理该请求。  
   
   3. 服务器向客户端返回应答 
   
   ​	一次消息的发送耗时是上述三个步骤的总和。 在一些对速度要求高，但是可靠性要求不高的场景下，比如日志收集类应用， 可以采用Oneway方式发送 
   
   ​		Oneway方式只发送请求不等待应答，即**将数据写入客户端的Socket缓冲区就返回**，不等待对方返 回结果。 用这种方式发送消息的耗时可以缩短到微秒级。 

​		另一种提高发送速度的方法是增加Producer的并发量，使用多个Producer同时发送，我们不用担心多Producer同时写会降低消息写磁盘的效率，RocketMQ引入了一个并发窗口，在窗口内消息可以并发地写入DirectMem中，然后异步地将连续一段无空洞的数据刷入文件系统当中。 

​		顺序写CommitLog可让RocketMQ无论在HDD还是SSD磁盘情况下都能保持较高的写入性能。 

​		目前在阿里内部经过调优的服务器上，写入性能达到90万+的TPS，我们可以参考这个数据进行系统优化。 

​		在Linux操作系统层级进行调优，推荐使用EXT4文件系统，IO调度算法使用deadline算法。

- **消息发送高可用：**

​		在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，

不同brokerId的机器组成一个Broker组），这样既可以在性能方面具有扩展性，也可以降低主节点故障

对整体上带来的影响，而且当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer

仍然可以发送消息的。

RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足，需要把Slave转成Master。 

1. 手动停止Slave角色的Broker。 

2. 更改配置文件。

3. 用新的配置文件启动Broker。

- **消息发送负载均衡**

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-30_23-32-31.png)

  ​		如图所示，一个Topic5 个队列可以部署在一台机器上，也可以分别部署在 5 台不同的机器上，发送消息

  通过轮询队列的方式 发送，每个队列接收平均的消息量。通过增加机器，可以水平扩展队列容量。 另外也可

  以自定义方式选择发往哪个队列。

  ```shell
  # 创建主题 
  [root@node1 ~]mqadmin updateTopic -n localhost:9876 -t tp_demo_02 -w 6 -b localhost:10911
  ```

  ```java
  DefaultMQProducer producer = new DefaultMQProducer("producer_grp_02"); producer.setNamesrvAddr("node1:9876");
  producer.start(); 
  Message message = new Message(); 
  message.setTopic("tp_demo_02"); 
  message.setBody("hello lagou".getBytes()); 
  // 指定MQ 
  SendResult result = producer.send(message, new MessageQueue("tp_demo_06", "node1", 5), 1_000 );
  System.out.println(result.getSendStatus()); 
  producer.shutdown();
  ```

  

###### **消息可靠**

RocketMQ支持消息的高可靠，影响消息可靠性的几种情况： 

1. Broker非正常关闭 
2. Broker异常Crash
3. OS Crash 
4. 机器掉电，但是能立即恢复供电情况 
5. 机器无法开机（可能是cpu、主板、内存等关键设备损坏）
6. 磁盘设备损坏

1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息

不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。

5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。

RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可

能丢失。

通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场

合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。

###### **事务消息**

​		RocketMQ事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。比如银行转账， A银行的某账户要转一万元到B银行的某账户。A银行发送“B银行账户增加一万元”这个消息，要和“从A银 行账户扣除一万元”这个操作同时成功或者同时失败。

​		RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致性。

​		RocketMQ采用两阶段提交的方式实现事务消息，TransactionMQProducer处理上面情况的流程是，先发一个“准备从B银行账户增加一万元”的消息，发送成功后做从A银行账户扣除一万元的操作，根据操作结果是否成功，确定之前的“准备从B银行账户增加一万元”的消息是做commit还是rollback，具 体流程如下：

- 发送方向RocketMQ发送“待确认”消息。

- RocketMQ将收到的“待确认”消息持久化成功后，向发送方回复消息已经发送成功，此时第一阶段消息发送完成。

- 发送方开始执行本地事件逻辑。 

- 发送方根据本地事件执行结果向RocketMQ发送二次确认（Commit或是Rollback）消息， RocketMQ收到Commit状态则将第一阶段消息标记为可投递，订阅方将能够收到该消息；收到Rollback状态则删除第一阶段的消息，订阅方接收不到该消息。 

- 如果出现异常情况，步骤4）提交的二次确认最终未到达RocketMQ，服务器在经过固定时间段后将对“待确认”消息发起回查请求。 

- 发送方收到消息回查请求后（如果发送一阶段消息的Producer不能工作，回查请求将被发送到和Producer在同一个Group里的其他Producer），通过检查对应消息的本地事件执行结果返回Commit 或Roolback状态。

- RocketMQ收到回查请求后，按照步骤4）的逻辑处理。

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_20-22-13.png)

  ​		上面的逻辑似乎很好地实现了事务消息功能，它也是RocketMQ之前的版本实现事务消息的逻辑。 但是因为RocketMQ依赖将数据顺序写到磁盘这个特征来提高性能，步骤4）却需要更改第一阶段消息 的状态，这样会造成磁盘Catch的脏页过多，降低系统的性能。所以RocketMQ在4.x的版本中将这部分 功能去除。系统中的一些上层Class都还在，用户可以根据实际需求实现自己的事务功能。 

  ​		客户端有三个类来支持用户实现事务消息，第一个类是LocalTransaction-Executer，用来实例化步 骤3）的逻辑，根据情况返回LocalTransactionState.ROLLBACK_MESSAGE或者 LocalTransactionState.COMMIT_MESSAGE状态。第二个类是TransactionMQProducer，它的用法和 DefaultMQProducer类似，要通过它启动一个Producer并发消息，但是比DefaultMQProducer多设置本地事务处理函数和回查状态函数。第三个类是TransactionCheckListener，实现步骤5）中MQ服务器的回查请求，返回LocalTransactionState.ROLLBACK_MESSAGE或者LocalTransactionState.COMMIT_MESSAGE

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_20-27-03.png)

  **RocketMQ事务消息设计**

  - 事务消息在一阶段对用户不可见 

    ​		在RocketMQ事务消息的主要流程中，一阶段的消息如何对用户不可见。其中，事务消息相对普通 消息最大的特点就是一阶段发送的消息对用户是不可见的。那么，如何做到写入消息但是对用户不可见呢？RocketMQ事务消息的做法是：如果消息是half消息，将备份原消息的主题与消息消费队列，然后 改变主题为RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费half类型的 消息。然后二阶段会显示执行提交或者回滚half消息（逻辑删除）。当然，为了防止二阶段操作失败， RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费，根 据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。 

    ​		在RocketMQ中，消息在服务端的存储结构如下，每条消息都会有对应的索引信息，Consumer通过ConsumeQueue这个二级索引来读取消息实体内容，其流程如下：

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_20-31-28.png)

    ​		RocketMQ的具体实现策略是：写入的如果事务消息，对消息的Topic和Queue等属性进行替换， 同时将原来的Topic和Queue信息存储到消息的属性中，正因为消息主题被替换，故消息并不会转发到 该原主题的消息消费队列，消费者无法感知消息的存在，不会消费。其实改变消息主题是RocketMQ的 常用“套路”，回想一下延时消息的实现机制。RMQ_SYS_TRANS_HALF_TOPIC
    
  - Commit和Rollback操作以及Op消息的引入
  
    ​		在完成一阶段写入一条对用户不可见的消息后，二阶段如果是Commit操作，则需要让消息对用户
  
    可见；如果是Rollback则需要撤销一阶段的消息。先说Rollback的情况。对于Rollback，本身一阶段的
  
    消息对用户是不可见的，其实不需要真正撤销消息（实际上RocketMQ也无法去真正的删除一条消息，
  
    因为是顺序写文件的）。但是区别于这条消息没有确定状态（Pending状态，事务悬而未决），需要一
  
    个操作来标识这条消息的最终状态。RocketMQ事务消息方案中引入了Op消息的概念，用Op消息标识
  
    事务消息已经确定的状态（Commit或者Rollback）。如果一条事务消息没有对应的Op消息，说明这个
  
    事务的状态还无法确定（可能是二阶段失败了）。引入Op消息后，事务消息无论是Commit或者
  
    Rollback都会记录一个Op操作。Commit相对于Rollback只是在写入Op消息前创建Half消息的索引。
  
  - Op消息的存储和对应关系
  
    ​		RocketMQ将Op消息写入到全局一个特定的Topic中通过源码中的方法—
  
    TransactionalMessageUtil.buildOpTopic()；这个Topic是一个内部的Topic（像Half消息的Topic一
  
    样），不会被用户消费。Op消息的内容为对应的Half消息的存储的Offset，这样通过Op消息能索引到
  
    Half消息进行后续的回查操作。
  
  - Half消息的索引构建
  
    ​		在执行二阶段Commit操作时，需要构建出Half消息的索引。一阶段的Half消息由于是写到一个特
  
    殊的Topic，所以二阶段构建索引时需要读取出Half消息，并将Topic和Queue替换成真正的目标的
  
    Topic和Queue，之后通过一次普通消息的写入操作来生成一条对用户可见的消息。所以RocketMQ事
  
    务消息二阶段其实是利用了一阶段存储的消息的内容，在二阶段时恢复出一条完整的普通消息，然后走
  
    一遍消息写入流程。
  
  - 如何处理二阶段失败的消息？
  
    ​		如果在RocketMQ事务消息的二阶段过程中失败了，例如在做Commit操作时，出现网络问题导致
  
    Commit失败，那么需要通过一定的策略使这条消息最终被Commit。RocketMQ采用了一种补偿机制，
  
    称为“回查”。Broker端对未确定状态的消息发起回查，将消息发送到对应的Producer端（同一个Group
  
    的Producer），由Producer根据消息来检查本地事务的状态，进而执行Commit或者Rollback。
  
    Broker端通过对比Half消息和Op消息进行事务消息的回查并且推进CheckPoint（记录那些事务消息的
  
    状态是确定的）。
  
    ​		值得注意的是，rocketmq并不会无休止的的信息事务状态回查，**默认回查15次**，如果15次
  
    回查还是无法得知事务状态，rocketmq默认回滚该消息。
  
  事务消息代码：
  
  TxProducer.java
  
  ```java
  package com.lagou.rocket.demo.producer; 
  import org.apache.rocketmq.client.exception.MQClientException; 
  import org.apache.rocketmq.client.producer.LocalTransactionState; 
  import org.apache.rocketmq.client.producer.TransactionListener; 
  import org.apache.rocketmq.client.producer.TransactionMQProducer; 
  import org.apache.rocketmq.common.message.Message; 
  import org.apache.rocketmq.common.message.MessageExt; 
  public class TxProducer { public static void main(String[] args) throws MQClientException { 
      TransactionListener listener = new TransactionListener() { 
          @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
              // 当发送事务消息prepare(half)成功后，调用该方法执行本地事务
              System.out.println("执行本地事务，参数为：" + arg); 
              try {
                  Thread.sleep(100000); 
              } catch (InterruptedException e) { 
                  e.printStackTrace(); 
              } 
              // return LocalTransactionState.ROLLBACK_MESSAGE; 
              return LocalTransactionState.COMMIT_MESSAGE; 
          }
          @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) {
              // 如果没有收到生产者发送的Half Message的响应，broker发送请求到生产 者回查生产者本地事务的状态 
              // 该方法用于获取本地事务执行的状态。 
              System.out.println("检查本地事务的状态：" + msg); 
              return LocalTransactionState.COMMIT_MESSAGE; 
              // return LocalTransactionState.ROLLBACK_MESSAGE; 
          } 
      };
      TransactionMQProducer producer = new TransactionMQProducer("tx_producer_grp_08");
      producer.setTransactionListener(listener); 
      producer.setNamesrvAddr("node1:9876");
      producer.start(); 
      Message message = null; 
      message = new Message("tp_demo_08", "hello lagou - tx".getBytes());
      producer.sendMessageInTransaction(message, " {\"name\":\"zhangsan\"}"); 
  	} 
   }
  ```
  
  TxConsumer.java
  
  ```java
  package com.lagou.rocket.demo.consumer; 
  import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer; 
  import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext; 
  import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus; 
  import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently; import org.apache.rocketmq.client.exception.MQClientException; 
  import org.apache.rocketmq.common.message.MessageExt; 
  import java.util.List; 
  public class TxConsumer { 
      public static void main(String[] args) throws MQClientException {
          DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("txconsumer_grp_08_01"); 
          consumer.setNamesrvAddr("node1:9876"); 
          consumer.subscribe("tp_demo_08", "*"); 
          consumer.setMessageListener(new MessageListenerConcurrently() { 
              @Override 
              public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) { 
                  for (MessageExt msg : msgs) { 
                      System.out.println(new String(msg.getBody())); 
                  }
                  return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; 
              } 
          }); 
          consumer.start(); 
      } 
  }
  ```

###### **消息重投**

生产者在发送消息时：

1. 同步消息失败会重投
2. 异步消息有重试
3. oneway没有任何保证。

消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是

无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大

概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。

如下方法可以设置消息重投策略：

1. retryTimesWhenSendFailed：同步发送失败重投次数，默认为2，因此生产者会最多尝试发送

retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度

保证消息不丢失。超过重投次数，抛异常，由客户端保证消息不丢失。当出现RemotingException、

MQClientException和部分MQBrokerException时会重投。重试总耗时不超过sendMsgTimeout设置的值，默认

10s，如果本身向broker发送消息产生超时异常，就不会再重试。

2. retryTimesWhenSendAsyncFailed：异步发送失败重试次数，异步重试不会选择其他broker，

仅在同一个broker上做重试，不保证消息不丢。

3. retryAnotherBrokerWhenNotStoreOK：消息刷盘（主或备）超时或slave不可用（返回状态非

SEND_OK），是否尝试发送到其他broker，默认false。十分重要消息可以开启。

​		以上策略也是在一定程度上保证了消息可以发送成功。如果业务对消息可靠性要求比较高，建议应

用增加相应的重试逻辑：比如调用send同步方法发送失败时，则尝试将消息存储到db，然后由后台线

程定时重试，确保消息一定到达Broker。

​		上述db重试方式为什么没有集成到MQ客户端内部做，而是要求应用自己去完成，主要基于以下几

点考虑：

1. MQ的客户端设计为无状态模式，方便任意的水平扩展，且对机器资源的消耗仅仅是cpu、内存、网络。

2. 如果MQ客户端内部集成一个KV存储模块，那么数据只有同步落盘才能较可靠，而同步落盘本身性能开销较

   大，所以通常会采用异步落盘，又由于应用关闭过程不受MQ运维人员控制，可能经常会发生 kill -9 这样暴力

   方式关闭，造成数据没有及时落盘而丢失。

3. Producer所在机器的可靠性较低，一般为虚拟机，不适合存储重要数据。综上，建议重试过程交由应用来控制。

###### **流量控制**

当Broker处理能力到达瓶颈时会产生生产者流控：

1. commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，发生流控。
2. 如果开启transientStorePoolEnable = true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，发生流控。
3. broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，发生流控。
4. broker通过拒绝send 请求方式实现流量控制。

注意，**生产者流控，不会尝试消息重投。** 

##### 3.2.4 Consumer 消息消费者

> ​		结点无状态，可集群部署。Consumer启动时，随机与Name Server集群中的一个结点建立长连接 ，并定期从Name Server获取Topic路由信息，并与提供Topic服务的Broker Master结点和Master Slave结点建立长连接，且定时向Broker Master结点和Borker Slave结点发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。收发消息前，先创建Topic，创建Topic时需要制定该Topic要存储在哪些Broker上 ，也可以在发送消息时自动创建Topic。

######  ConsumerGroup

​		同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例**必须订阅完全相同的Topic**。RocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broadcasting）。

###### 消息订阅

​		是指Consumer关注了某个Topic中带有某些Tag标签的消息

###### **消息顺序**

​		指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。

​		消费消息的顺序要同发送消息的顺序一致，在RocketMQ 中主要指的是局部顺序，即一类消息为满足顺序性，必须Producer单线程顺序发送，且发送到同一个队列，这样Consumer 就可以按照Producer发送的顺序去消费消息。

- 普通顺序消息

  ​		顺序消息的一种，正常情况下可以保证完全的顺序消息，但是一旦发生通信异常，Broker 重启，由于队列总数发生发化，哈希取模后定位的队列会发化，产生短暂的消息顺序不一致。 如果业务能容忍在集群异常情况(如某个Broker 宕机或者重启)下，消息短暂的乱序，使用普通顺序方式比较合适。

- 严格顺序消息

  ​		顺序消息的一种，无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。 如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不过仍然会存在几分钟的服务不可用。(依赖同步双写，主备自动切换，自动切换功能目前还未实现)目前已知的应用只有数据库 binlog 同步强依赖严格顺序消息，其他应用绝大部分都可以容忍短暂乱序，推荐使用普通的顺序消息。
  
- 局部有序

  ​		只要保证每一组消息被顺序消费即可，比如上面订单消息的例子，只要保证同一 个订单ID的三个消息能按顺序消费即可。

- 全局有序

  ​		指某个Topic下的所有消息都要保证顺序；

  在多数的业务场景中实际只需要局部有序就可以了

  Rocket在默认情况下不保证顺序序，比如创建一个Topic，默认八个写队列，八个读队列。

这时 候一条消息可能被写入任意一个队列里；在数据的读取过程中，可能有多个Consumer，每

个 Consumer也可能启动多个线程并行处理，所以消息被哪个Consumer消费，被消费的顺序和

写入的顺 序是否一致是不确定的。

​		要保证全局顺序消息，需要先把Topic的读写队列数设置为一，然后Producer和Consumer的

并发 设置也要是一。简单来说，为了保证整个Topic的全局消息有序，只能消除所有的并发处理，

各部分都 设置成单线程处理。

​		要保证部分消息有序，需要发送端和消费端配合处理。在发送端，要做到把同一业务ID的消息

发送 到同一个Message Queue；在消费过程中，要做到从同一个Message Queue读取的消息不

被并发处 理，这样才能达到部分有序。消费端通过使用MessageListenerOrderly类来解决单

Message Queue的 消息被并发处理的问题。原理如下图所示：

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_19-35-54.png)

​		Consumer使用MessageListenerOrderly的时候，下面四个Consumer的设置依旧可以使用： 

- setConsumeThreadMin 设置消费者最小线程数
- setConsumeThreadMax  设置消费者最大线程数
- setPullBatchSize  设置拉取消息批次大小
- setConsumeMessageBatchMaxSize 设置推送消息批次大小

​        前两个参数设置Consumer的线程数； PullBatchSize指的是一次从Broker的一个Message 

Queue获取消息的最大数量，默认值是32； ConsumeMessageBatchMaxSize指的是这个

Consumer的Executor（也就是调用 MessageListener处理的地方）一次传入的消息数

（Listmsgs这个链表的最大长度）， 默认值是1。 上述四个参数可以使用，说明

MessageListenerOrderly并不是简单地禁止并发处理。在 MessageListenerOrderly的实现中，

为每个Consumer Queue加个锁，消费每个消息前，需要先获得 这个消息对应的Consumer 

Queue所对应的锁，这样保证了同一时间，同一个Consumer Queue的消息不被并发消费，但不

同Consumer Queue的消息可以并发处理。		

###### **至少一次**

​		至少一次(At least Once)指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。

###### **回溯消费**

​		回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于

Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时

间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒。

###### **定时消息**

​		定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的Topic。

​		Broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级msg.setDelayLevel(level)即可。

​		level有以下三种情况：

1. level == 0，消息为非延迟消息

2. 1<=level<=maxLevel，消息延迟特定时间，例如level==1，延迟1s

3. level > maxLevel，则level== maxLevel，例如level==20，延迟2h

   ​	定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的
   
   queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟
   
   的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。
   
   需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都
   
   会变高。
   
   查看SCHEDULE_TOPIC_XXXX主题信息：
   
   ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_17-10-44.png)
   
   Producer：
   
   ```java
   public class MyProducer {
   	public static void main(String[] args) throws MQClientException,RemotingException, InterruptedException, MQBrokerException {
   		DefaultMQProducer producer = new DefaultMQProducer("producer_grp_06_01");
   		producer.setNamesrvAddr("node1:9876");
   		producer.start();
   		Message message = null;
   		for (int i = 0; i < 20; i++) {
   			// 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h
   			message = new Message("tp_demo_06", ("hello lagou - " + i).getBytes());
   			// 设置延迟级别，0表示不延迟，大于18的总是延迟2h
   			message.setDelayTimeLevel(i);
   			producer.send(message);
   		}
   		producer.shutdown();
   	}
   }
   ```
   
   Consumer：
   
   ```java
   public class MyConsumer {
   	public static void main(String[] args) throws MQClientException {
   		DefaultMQPushConsumer consumer = new
   		DefaultMQPushConsumer("consumer_grp_06_01");
   		consumer.setNamesrvAddr("node1:9876");
   		consumer.subscribe("tp_demo_06", "*");
   		consumer.setMessageListener(new MessageListenerConcurrently() {
   			@Override
   			public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyContext context) {
   				System.out.println(System.currentTimeMillis() / 1000);
   				for (MessageExt msg : msgs) {
                       System.out.println(
                       msg.getTopic() + "\t"
                       + msg.getQueueId() + "\t"
                       + msg.getMsgId() + "\t"
                       + msg.getDelayTimeLevel() + "\t"
                       + new String(msg.getBody())
                       );
                   }
                   return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
   			}
   		});
   		consumer.start();
   	}
   }
   ```
   
   

###### **消息重试**

Consumer消费消息失败后，支持消息重新消费。

消息消费失败后，消息重试有两种模式：

1. 等待一定时间，重新消费当前消息。

   > 这种情况适用于由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。

2. 等待一定时间，跳过当前消息，消费下一条消息。

   > 这种情况适用于)由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功。

根据消息类型，又分为顺序消息的重试和无序消息的重试

- **顺序消息的重试**

  ​		对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次 间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应 用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。

  ```java
  DefaultMQPushConsumer consumer = new
  DefaultMQPushConsumer("consumer_grp_04_01");
  consumer.setNamesrvAddr("node1:9876");
  consumer.setConsumeMessageBatchMaxSize(1);
  consumer.setConsumeThreadMin(1);
  consumer.setConsumeThreadMax(1);
  // 消息订阅
  consumer.subscribe("tp_demo_04", "*");
  // 并发消费
  // consumer.setMessageListener(new essageListenerConcurrently() {
  // @Override
  // public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt>msgs, ConsumeConcurrentlyContext context) {
  // return null;
  // }
  // });
  // 顺序消费
  consumer.setMessageListener(new MessageListenerOrderly() {
  @Override
  public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs,ConsumeOrderlyContext context) {
  		for (MessageExt msg : msgs) {
  			System.out.println(msg.getMsgId() + "\t" + msg.getQueueId() +  "\t" + new String(msg.getBody()));
          
  		}
  		return null;
  	}
  });
  consumer.start();
  ```

- **无序消息的重试**

  ​		对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。 

  ​		无序消息的重试**只针对集群消费方式生效**；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。

- **重试次数**

  消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_14-32-24.png)

  ​		如果消息重试 16 次后仍然失败，消息将不再投递。如果严格按照上述重试时间间隔计算，某条消 息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围 消息将不再重试投递。 

  ​		**注意：** 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。

- **配置方式**

  ​		**消费失败后，重试配置方式**

  ​		集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置 （三种方式任选一种）： 

  - 返回 ConsumeConcurrentlyStatus.RECONSUME_LATER; （推荐） 

  - 返回 Null 

  - 抛出异常

    ```java
    public class MyConcurrentlyMessageListener implements
    MessageListenerConcurrently {
    	@Override
    	public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,
    ConsumeConcurrentlyContext context) {
            
    		//处理消息
    		doConsumeMessage(msgs);
    		//方式1：返回ConsumeConcurrentlyStatus.RECONSUME_LATER，消息将重试
    		return ConsumeConcurrentlyStatus.RECONSUME_LATER;
    		//方式2：返回 null，消息将重试
    		return null;
    		//方式3：直接抛出异常， 消息将重试
    		throw new RuntimeException("Consumer Message exceotion");
    	}
    }
    
    ```

    **消费失败后，不重试配置方式**

    集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，

  最终返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS，此后这条消息将不会再

  重试。

  ```java
  public class MyConcurrentlyMessageListener implements
  MessageListenerConcurrently {
  	@Override
  	public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyContext context) {
  		try {
  			doConsumeMessage(msgs);
  		} catch (Throwable e) {
  			//捕获消费逻辑中的所有异常，并返回
  			ConsumeConcurrentlyStatus.CONSUME_SUCCESS
  			return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
  		}
  		//消息处理正常，直接返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS
  		return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
  	}
  }			
  ```

  ​		**自定义消息最大重试次数**

  ​		消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略： 

  - 最大重试次数小于等于 16 次，则重试时间间隔同上表描述。 

  - 最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。

    ```java
    DefaultMQPushConsumer consumer = new
    DefaultMQPushConsumer("consumer_grp_04_01");
    // 设置重新消费的次数
    // 共16个级别，大于16的一律按照2小时重试
    consumer.setMaxReconsumeTimes(20);
    ```

    **注意：**

  - 消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。 

  - 如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。 

  - 配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置

    **获取消息重试次数**

    消费者收到消息后，可按照如下方式获取消息的重试次数：

    ```java
    public class MyConcurrentlyMessageListener implements
    MessageListenerConcurrently {
    	@Override
    	public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyContext context) {
    		for (MessageExt msg : msgs) {
    			System.out.println(msg.getReconsumeTimes());
    		}
    		doConsumeMessage(msgs);
    		return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    	}
    }
    ```

    

###### **死信队列**

​		死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消

息重试；达到最大重试次数后(默认16此)，若消费依然失败，则表明消费者在正常情况下无法正确

地消费该消息，此时，消息队列 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列

中。RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），

将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过

使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。

​		在控制台Topic列表中看到"DLQ"相关的Topic，默认命名是：

- %RETRY%消费组名称（重试Topic）

- %DLQ%消费组名称（死信Topic）

  死信队列也可以被订阅和消费，并且也会过期

  可视化工具：rocketmq-console下载地址：

  https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip

  使用jdk8：

  ```shell
  # 编译打包
  mvn clean package -DskipTests
  # 运行工具
  java -jar target/rocketmq-console-ng-1.0.0.jar
  ```

  页面设置NameSrv地址即可。如果不生效，就直接修改项目的application.properties中的 

namesrv地址选项的值。

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_15-14-14.png)

1. **死信特性**

   死信消息具有以下特性 

   - 不会再被消费者正常消费。 
   - 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。 

   死信队列具有以下特性：

   -  一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。 

   - 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。

   -  一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。

2. 查看死信消息

   - 在控制台查询出现死信队列的主题信息

     ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_15-18-21.png)

   - 在消息界面根据主题查询死信消息

     ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_15-18-54.png)

   - 选择重新发送消息

     ​		一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，

     通常需要您对其 进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 

     RocketMQ 控制台重新发送该消息，让消费者重新消费一次。

###### **流量控制**

​			消费者在消费能力达到瓶颈时会产生流控。

1. 消费者本地缓存消息数超过pullThresholdForQueue时，默认1000。

2. 消费者本地缓存消息大小超过pullThresholdSizeForQueue时，默认100MB。

3. 消费者本地缓存消息跨度超过consumeConcurrentlyMaxSpan时，默认2000。

4. 消费者流控的结果是降低拉取频率。

   ​		在 Apache RocketMQ 中，当消费者去消费消息的时候，无论是通过 pull 的方式还是 push 的方

   式，都可能会出现大批量的消息突刺。如果此时要处理所有消息，很可能会导致系统负载过高，影响稳

   定性。但其实可能后面几秒之内都没有消息投递，若直接把多余的消息丢掉则没有充分利用系统处理消

   息的能力。我们希望可以把消息突刺均摊到一段时间内，让系统负载保持在消息处理水位之下的同时尽

   可能地处理更多消息，从而起到“削峰填谷”的效果：

   ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_18-01-10.png)

   ​		上图中红色的部分代表超出消息处理能力的部分。我们可以看到消息突刺往往都是瞬时的、不规律

   的，其后一段时间系统往往都会有空闲资源。我们希望把红色的那部分消息平摊到后面空闲时去处理，

   这样既可以保证系统负载处在一个稳定的水位，又可以尽可能地处理更多消息。

######  消息消费

- **消费模式**

​		RocketMQ消息订阅有两种模式，一种是Push模式（MQPushConsumer），即MQServer主动向消费端推送；另外一种是Pull模式（MQPullConsumer），即消费端在需要时，主动到MQ Server拉取。但在具体实现时，Push和Pull模式本质都是采用消费端主动拉取的方式，即consumer轮询从broker拉取消息。

​		Push模式特点:好处就是实时性高。不好处在于消费端的处理能力有限，当瞬间推送很多消息给消费端时，容易造成消费端的消息积压，严重时会压垮客户端。

​		Pull模式好处就是主动权掌握在消费端自己手中，根据自己的处理能力量力而行。缺点就是如何控制Pull的频率。定时间隔太久担心影响时效性，间隔太短担心做太多“无用功”浪费资源。比较折中的办法就是长轮询。

​		Push模式与Pull模式的区别:

1. Push方式里，consumer把长轮询的动作封装了，并注册MessageListener监听器，取到消息后，唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉消息是被推送过来的。
2. Pull方式里，取消息的过程需要用户自己主动调用，首先通过打算消费的Topic拿到MessageQueue的集合，遍历MessageQueue集合，然后针对每个MessageQueue批量取消息，一次取完后，记录该队列下一次要取的开始offset，直到取完了，再换另一个MessageQueue。

**RocketMQ使用长轮询机制来模拟Push效果，算是兼顾了二者的优点。**

​	根据消费模式不同，Consumer又分为PullConsumer和PushConsumer：

1. PullConsumer：Consumer消费的一种类型，应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。
2. PushConsumer：Consumer消费的一种类型，该模式下Broker收到数据后会主动推送给消费端。应用通常向Consumer对象注册一个Listener接口，一旦收到消息，Consumer对象立刻回调Listener接口方法。该消费模式一般实时性较高。

- **广播消费**

​		一条消息被多个 Consumer 消费，即使这些 Consumer 属于同一个 Consumer Group，消息也会被 Consumer Group 中的每个 Consumer 都消费一次，广播消费中的 Consumer Group 概念可以认为在消息划分方面无意义。在 CORBA Notification 规范中，消费方式都属于广播消费。在 JMS 规范中，相当于 JMS Topic（ publish/subscribe ）模型。

- **集群消费**

​		一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其中一个 Consumer Group 有 3 个实例(可能是 3 个进程，或者3台机器)，那举每个实例只消费其中的 3条消息。

简单总结消费的几个要点： 

1. 消息消费方式（Pull和Push） 

2. 消息消费的模式（广播模式和集群模式） 

3. 流量控制（可以结合sentinel来实现，后面单独讲） 

4. 并发线程数设置 

5. 消息的过滤（Tag、Key） TagA||TagB||TagC * null 

   

​         当Consumer的处理速度跟不上消息的产生速度，会造成越来越多的消息积压，这个时候首先查看消费逻辑本身有没有优化空间，除此之外还有三种方法可以提高Consumer的处理能力。 

1. 提高消费并行度 

   在同一个ConsumerGroup下（Clustering方式），可以通过增加Consumer实例的数量来提高并行度。 

   通过加机器，或者在已有机器中启动多个Consumer进程都可以增加Consumer实例数。 

   注意：总的Consumer数量不要超过Topic下Read Queue数量，超过的Consumer实例接收不到消息。 

   此外，通过提高单个Consumer实例中的并行处理的线程数，可以在同一个Consumer内增加 并行度来提高吞吐量（设置方法是修改consumeThreadMin和consumeThreadMax）。 

2. 以批量方式进行消费 

   某些业务场景下，多条消息同时处理的时间会大大小于逐个处理的时间总和，比如消费消息中涉及update某个数据库，一次update10条的时间会大大小于十次update1条数据的时间。 

   可以通过批量方式消费来提高消费的吞吐量。实现方法是设置Consumer的 consumeMessageBatchMaxSize这个参数，默认是1，如果设置为N，在消息多的时候每次收到的是个长度为N的消息链表。 

3. 检测延时情况，跳过非重要消息 

   Consumer在消费的过程中，如果发现由于某种原因发生严重的消息堆积，短时间无法消除堆 积，这个时候可以选择丢弃不重要的消息，使Consumer尽快追上Producer的进度。

- **消息消费高可用**

  ​		在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁

  忙的时候，Consumer会被**自动切换**到从Slave 读。

  ​		有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从

  Slave读取消息，不影响Consumer程序。

  ​		这就达到了消费端的高可用性。

- **消费过程幂等**

  ​		RocketMQ无法避免消息重复（Exactly-Once），所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理。

  ​		可以借助关系数据库进行去重。首先需要确定消息的唯一键，可以是msgId，也可以是消息内容中的唯一

  标识字段，例如订单Id等。

  ​		在消费之前判断唯一键是否在关系数据库中存在。如果不存在则插入，并消费，否则跳过。（实际过程要考虑原子性问题，判断是否存在可以尝试插入，如果报主键冲突，则插入失败，直接跳过）

  ​		msgId一定是全局唯一标识符，但是实际使用中，可能会存在相同的消息有两个不同msgId的情况（生产者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行防重复消费。

- **消费速度慢的处理方式**

  - **提高消息并行度**

    ​		绝大部分消息消费行为都属于IO密集型，即可能是操作数据库，或者调用RPC，这类消费行为的消

    费速度在于后端数据库或者外系统的吞吐量。

    ​		通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，**反而会下降**。所以，

    应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法：

    - 同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅

      队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。

    - 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax实现。

    - 丢弃部分不重要的消息

  - 批量方式消费

    ​		某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量。

    ​		例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可

    大幅度提高消费的吞吐量，通过设置 consumer的 consumeMessageBatchMaxSize 返个参数，默认是 

    1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。

  - 跳过非重要消息

    ​		发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢

    弃不重要的消息。

    ​		例如，当某个队列的消息数堆积到100000条以上，则尝试丢弃部分或全部消息，这样就可以快速追

    上发送消息的速度。示例代码如下：

    ```java
    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) { 
        long offset = msgs.get(0).getQueueOffset(); 
        String maxOffset = msgs.get(0).getProperty(Message.PROPERTY_MAX_OFFSET); 
        long diff = Long.parseLong(maxOffset) - offset; 
        if (diff > 100000) { 
            // TODO 消息堆积情况的特殊处理 
            return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; 
        }
        // TODO 正常消费过程 
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; 
    }
    ```

- **消息消费负载均衡**

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-30_23-36-23.png)

  ​		如图所示，TOPIC_A如果有 5 个队列，2 个 consumer，那么第一个 Consumer 消费 3 个队列，第二

  consumer 消费 2 个队列。 这样即可达到平均消费的目的，可以水平扩展 Consumer 来提高消费能力。但是 

  Consumer 数量要小于等于队列数 量，如果 Consumer 超过队列数量，那么多余的Consumer 将不能消费消

  息 。 

  ​		在RocketMQ中，Consumer端的两种消费模式（Push/Pull）底层都是基于拉模式来获取消息的，而在

  Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到

  消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。

  ​		如果未拉取到消息，则延迟一下又继续拉取。

  ​		在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端在知道从Broker端的哪一个消息队

  列中去获取消息。

  ​		因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个

  ConsumerGroup中的哪些Consumer消费。

  ​		要做负载均衡，必须知道一些全局信息，也就是一个ConsumerGroup里到底有多少个Consumer。

  ​		知道了全局信息，才可以根据某种算法来分配，比如简单地平均分到各个Consumer。 

  ​		在RocketMQ中，负载均衡或者消息分配是在Consumer端代码中完成的，**Consumer**从Broker处获得全

  局信息，然后**自己做负载均衡**，只处理分给自己的那部分消息。

  ​		Pull Consumer可以看到所有的Message Queue，而且从哪个Message Queue读取消息，读消息时的

  Offset都由使用者控制，使用者可以实现任何特殊方式的负载均衡。DefaultMQPullConsumer有两个辅助方

  法可以帮助实现负载均衡，一个是registerMessageQueueListener函数，一个是

  MQPullConsumerScheduleService（使用这个Class类似使用DefaultMQPushConsumer，但是它把Pull消

  息的主动性留给了使用者）。

  ```java
  public class MyConsumer { 
      public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException, MQBrokerException { 
          DefaultMQPullConsumer consumer = new DefaultMQPullConsumer("consumer_pull_grp_01"); 
          consumer.setNamesrvAddr("node1:9876"); 
          consumer.start(); 
          Set<MessageQueue> messageQueues = consumer.fetchSubscribeMessageQueues("tp_demo_01"); 
          for (MessageQueue messageQueue : messageQueues) { 
              // 指定从哪个MQ拉取数据 
              PullResult result = consumer.pull(messageQueue, "*", 0L, 10);
              List<MessageExt> msgFoundList = result.getMsgFoundList(); 
              for (MessageExt messageExt : msgFoundList) {
                  System.out.println(messageExt); 
              } 
          }
          consumer.shutdown(); 
      } 
  }
  ```

  ​		DefaultMQPushConsumer的负载均衡过程不需要使用者操心，客户端程序会自动处理，每个

  DefaultMQPushConsumer启动后，会马上会触发一个**doRebalance动作**；而且在同一个

  ConsumerGroup里加入新的DefaultMQPushConsumer时，各个Consumer都会被触发**doRebalance**动

  作。

  ​		负载均衡的**分配粒度只到Message Queue**，把Topic下的所有Message Queue分配到不同的

  Consumer中如下图所示，具体的负载均衡算法有几种，**默认用的AllocateMessageQueueAveragely**。 

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-06-30_23-47-06.png)

  我们可以设置负载均衡的算法：

  ```java
  DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("consumer_push_grp_01"); 
  consumer.setNamesrvAddr("node1:9876"); 
  // 设置负载均衡算法 
  consumer.setAllocateMessageQueueStrategy(new AllocateMessageQueueAveragely());
  consumer.setMessageListener(new MessageListenerConcurrently() { 
      @Override 
      public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) { 
          // todo 处理接收到的消息 
          return null; 
      } 
  }); 
  consumer.start();
  ```

  ​		以AllocateMessageQueueAveragely策略为例，如果创建Topic的时候，把Message Queue数设为3，当

  Consumer数量为2的时候，有一个Consumer需要处理Topic三分之二的消息，另一个处理三分之一的消息；

  当Consumer数量为4的时候，有一个Consumer无法收到消息，其他3个Consumer各处理Topic三分之一的消

  息。

  ​		可见Message Queue数量设置过小不利于做负载均衡，通常情况下，应把一个Topic的Message

  Queue数设置为16。 

  - Consumer端的心跳包发送

    在Consumer启动后，它就会通过**定时任务**不断地向RocketMQ集群中的所有Broker实例发送心跳包（其

    中包含了消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到

    Consumer的心跳消息后，会将它维护在ConsumerManager的本地缓存变量—consumerTable，同时并

    将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负

    载均衡提供可以依据的元数据信息。

  - Consumer端实现负载均衡的核心类—RebalanceImpl

    在Consumer实例的启动流程中启动MQClientInstance实例的部分，会完成负载均衡服务线程—

    RebalanceService的启动（每隔20s执行一次）

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-04-10.png)

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-05-20.png)

    ​		通过查看源码可以发现，RebalanceService线程的run()方法最终调用的是RebalanceImpl类的

    **rebalanceByTopic()**方法，该方法是实现Consumer端负载均衡的核心。

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-06-39.png)

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-07-22.png)

    ​		这里，rebalanceByTopic()方法根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。

    ​		对于集群模式：

    ```java
    case CLUSTERING: { 
        Set<MessageQueue> mqSet = this.topicSubscribeInfoTable.get(topic); 
        List<String> cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup); 
        if (null == mqSet) { 
            if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {
                log.warn("doRebalance, {}, but the topic[{}] not exist.", consumerGroup, topic); 
            } 
        }
        
        if (null == cidAll) { 
            log.warn("doRebalance, {} {}, get consumer id list failed", consumerGroup, topic); 
        }
        
        if (mqSet != null && cidAll != null) { 
            List<MessageQueue> mqAll = new ArrayList<MessageQueue>();
            mqAll.addAll(mqSet); 
            // 对MQ进行排序 
            Collections.sort(mqAll); 
            // 对消费者ID进行排序 
            Collections.sort(cidAll); 
            AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy;
            List<MessageQueue> allocateResult = null; 
            try {
                // 计算当前消费者应该分配的MQ集合 
                allocateResult = strategy.allocate( 
                    // 当前消费者所属的消费组 
                    this.consumerGroup, 
                    // 当前消费者ID
                    this.mQClientFactory.getClientId(), 
                    // MQ集合 
                    mqAll, 
                    // 消费组中消费者ID集合 
                    cidAll); 
            } catch (Throwable e) { 
                log.error("AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName={}", strategy.getName(), e); 
                return; 
            }
            Set<MessageQueue> allocateResultSet = new HashSet<MessageQueue>(); 
            if (allocateResult != null) { 
                allocateResultSet.addAll(allocateResult); 
            }
            boolean changed = this.updateProcessQueueTableInRebalance(topic, allocateResultSet, isOrder); 
            if (changed) { 
                log.info( "rebalanced result changed. allocateMessageQueueStrategyName={}, group={}, topic={}, clientId={}, mqAllSize={}, cidAllSize={}, rebalanceResultSize={}, rebalanceResultSet= {}", strategy.getName(), consumerGroup, topic, this.mQClientFactory.getClientId(), mqSet.size(), cidAll.size(), allocateResultSet.size(), allocateResultSet);
                this.messageQueueChanged(topic, mqSet, allocateResultSet); 
            } 
        }
        break; 
    }
    ```

    默认的负载均衡算法：

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-14-05.png)

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-14-54.png)

    AllocateMessageQueueAveragely是默认的MQ分配对象。

    算法：

    ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-01_00-15-35.png)

    ```java
    // 获取当前消费者在cidAll集合中的下标 
    int index = cidAll.indexOf(currentCID); 
    // mqAll对cidAll大小取模 
    int mod = mqAll.size() % cidAll.size(); 
    // 计算每个消费者应该分配到的mq数量 
    // 如果mq个数小于等于消费者个数，每个消费者最多分配一个mq 
    // 如果mq个数大于消费者个数， 
    int averageSize = 
        // 如果mq个数小于等于消费组中消费者个数 
        mqAll.size() <= cidAll.size() ? 
        // 平均数就是1 
        1: 
    	// 否则，看mod和index大小 
    	(
            mod > 0 && index < mod ? 
            	// 如果余数大于0并且当前消费者下标小于余数，则当前消费者应该消费平均数个mq+1
            mqAll.size() / cidAll.size() + 1 :
            // 如果余数大于0并且当前消费者下标大于等于余数，则当前消费者应该消费平均数个mq
            mqAll.size() / cidAll.size() 
        ); 
    // 计算当前消费者消费mq的起始位置 
    int startIndex = (mod > 0 && index < mod) 
        ?
        index * averageSize 
        :
    	index * averageSize + mod; 
    // 计算当前消费者消费mq的跨度，即当前消费者分几个MQ 
    int range = Math.min(averageSize, mqAll.size() - startIndex); 
    // 分配MQ，放到result集合中返回 
    for (int i = 0; i < range; i++) { 
        result.add(mqAll.get((startIndex + i) % mqAll.size())); 
    }
    return result;
    ```

    ​		消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在

    同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。
  
- **其他消费建议**

  - **关于消费者和订阅**

    ​		第一件需要注意的事情是，不同的消费组可以独立的消费一些 topic，并且每个消费组都有自己的消费偏移量。

    ​		确保同一组内的**每个消费者订阅信息保持一致**。

  - **关于有序消息**

    ​		消费者将锁定每个消息队列，以确保他们被逐个消费，虽然这将会导致性能下降，但是当你关心消息

    顺序的时候会很有用。

    ​		我们不建议抛出异常，你可以返回

    ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT 作为替代。

  - **关于并发消费**

    ​		顾名思义，消费者将并发消费这些消息，建议你使用它来获得良好性能，我们不建议抛出异常，你可

    以返回 ConsumeConcurrentlyStatus.RECONSUME_LATER 作为替代。

  - **关于消费状态Consume Status**

    ​	对于并发的消费监听器，你可以返回 RECONSUME_LATER 来通知消费者现在不能消费这条消息，并且

    希望可以稍后重新消费它。然后，你可以继续消费其他消息。对于有序的消息监听器，因为你关心它的顺

    序，所以不能跳过消息，但是你可以返回SUSPEND_CURRENT_QUEUE_A_MOMENT 告诉消费者等待片

    刻。

  - **关于Blocking**

    ​		不建议阻塞监听器，因为它会阻塞线程池，并最终可能会终止消费进程

  - **关于线程数设置**

    ​		消费者使用 ThreadPoolExecutor 在内部对消息进行消费，所以你可以通过setConsumeThreadMin

    或 setConsumeThreadMax 来改变它。

  - **关于消费位点**

    ​		当建立一个新的消费组时，需要决定是否需要消费已经存在于 Broker 中的历史消息。

    CONSUME_FROM_LAST_OFFSET 将会忽略历史消息，并消费之后生成的任何消息。

    CONSUME_FROM_FIRST_OFFSET 将会消费每个存在于 Broker 中的信息。也可以使用 

    CONSUME_FROM_TIMESTAMP 来消费在指定时间戳后产生的消息。

    ```java
    public static void main(String[] args) throws MQClientException { 
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("consumer_grp_15_01"); 
        consumer.setNamesrvAddr("node1:9886"); 
        consumer.subscribe("tp_demo_15", "*"); 
        // 以下三个选一个使用，如果是根据时间戳进行消费，则需要设置时间戳 
        // 从第一个消息开始消费，从头开始consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); 
        // 从最后一个消息开始消费，不消费历史消息
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); 
        // 从指定的时间戳开始消费
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_TIMESTAMP); 
        // 指定时间戳的值 
        consumer.setConsumeTimestamp(""); 
        consumer.setMessageListener(new MessageListenerConcurrently() { 
            @Override 
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) { 
                // TODO 处理消息的业务逻辑 
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; 
                // return ConsumeConcurrentlyStatus.RECONSUME_LATER; 
            } 
        }); 
        consumer.start(); 
    }
    ```

    

######  消息查询

​		RocketMQ支持按照下面两种维度（“按照Message Id查询消息”、“按照Message Key查询消息”）

进行消息查询。

- **按照MessageId查询消息**

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_14-08-57.png)

  ​		MsgId 总共 16 字节，包含消息存储主机地址（ip/port），消息 Commit Log offset。从 MsgId 中

  解析出 Broker 的地址和 Commit Log 的偏移地址，然后按照存储格式所在位置将消息 buffer 解析成一

  个完整的消息。

  ​		在RocketMQ中具体做法是：Client端从MessageId中解析出Broker的地址（IP地址和端口）和

  Commit Log的偏移地址后封装成一个RPC请求后，通过Remoting通信层发送（业务请求码：

  VIEW_MESSAGE_BY_ID）。Broker使用QueryMessageProcessor，使用请求中的 commitLog offset

  和 size 去 commitLog 中找到真正的记录并解析成一个完整的消息返回。

- **按照MessageKey查询消息**

  ​		主要是基于RocketMQ的IndexFile索引文件来实现的。RocketMQ的索引文件逻辑结构，类似JDK中

  HashMap的实现。索引文件的具体结构如下：

  ![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_14-11-25.png)

  - 根据查询的 key 的 hashcode%slotNum 得到具体的槽的位置（slotNum 是一个索引文件里面包

    含的最大槽的数目， 例如图中所示 slotNum=5000000）。

  - 根据 slotValue（slot 位置对应的值）查找到索引项列表的最后一项（倒序排列，slotValue 总是

    指向最新的一个索引项）。

  - 遍历索引项列表返回查询时间范围内的结果集（默认一次最大返回的 32 条记录）

  - Hash 冲突：

    - key 的 hash 值不同但模数相同，此时查询的时候会再比较一次 key 的 hash 值（每个索

      引项保存了 key 的 hash 值），过滤掉 hash 值不相等的项。

    - hash 值相等但 key 不等， 出于性能的考虑冲突的检测放到客户端处理（key 的原始值是

      存储在消息文件中的，避免对数据文件的解析）， 客户端比较一次消息体的 key 是否相同。

  - 存储；为了节省空间索引项中存储的时间是时间差值（存储时间-开始时间，开始时间存储在索引

    文件头中）， 整个索引文件是定长的，结构也是固定的。

  - API的使用

    ```java
    package com.lagou.rocket.demo.query; 
    import org.apache.rocketmq.client.consumer.DefaultMQPullConsumer; 
    import org.apache.rocketmq.client.exception.MQBrokerException; 
    import org.apache.rocketmq.client.exception.MQClientException; 
    import org.apache.rocketmq.common.message.MessageExt; 
    import org.apache.rocketmq.remoting.exception.RemotingException; 
    public class QueryingMessageDemo { 
        public static void main(String[] args) throws InterruptedException, RemotingException, MQClientException, MQBrokerException { 
            DefaultMQPullConsumer consumer = new DefaultMQPullConsumer("consumer_grp_09_01");
            consumer.setNamesrvAddr("node1:9876"); 
            consumer.start(); 
            MessageExt message = consumer.viewMessage("tp_demo_08", "0A4E00A7178878308DB150A780BB0000"); 
            System.out.println(message); 
            System.out.println(message.getMsgId()); 
            consumer.shutdown(); 
        } 
    }
    ```

######  消息优先级

​		有些场景，需要应用程序处理几种类型的消息，不同消息的优先级不同。RocketMQ是个先入先出

的队列，不支持消息级别或者Topic级别的优先级。业务中简单的优先级需求，可以通过间接的方式解

决，下面列举三种优先级相关需求的具体处理方法。

1. 多个不同的消息类型使用同一个topic时，由于某一个种消息流量非常大，导致其他类型的消息无法

   及时消费，造成不公平，所以把流量大的类型消息在一个单独的 Topic，其他类型消息在另外一个

   Topic，应用程序创建两个 Consumer，分别订阅不同的 Topic，这样就可以了。

2. 情况和第一种情况类似，但是不用创建大量的 Topic。举个实际应用场景: 一个订单处理系统，接收

   从 100家快递门店过来的请求，把这些请求通过 Producer 写入RocketMQ；订单处理程序通过

   Consumer 从队列里读取消 息并处理，每天最多处理 1 万单 。 如果这 100 个快递门店中某几个门店订

   单量 大增，比如门店一接了个大客户，一个上午就发出 2万单消息请求，这样其他 的 99 家门店可能被

   迫等待门店一的 2 万单处理完，也就是两天后订单才能被处 理，显然很不公平 。 

   这时可以创建一 个 Topic， 设置 Topic 的 MessageQueue 数 量 超过 100 个，Producer根据订

   单的门店号，把每个门店的订单写人 一 个 MessageQueue。 DefaultMQPushConsumer默认是采用

   循环的方式逐个读取一个 Topic 的所有 MessageQueue，这样如果某家门店订单量大增，这家门店对

   应的 MessageQueue 消息数增多，等待时间增长，但不会造成其他家门店等待时间增长。

   DefaultMQPushConsumer 默认的 pullBatchSize 是 32，也就是每次从某个 MessageQueue 读

   取消息的时候，最多可以读 32 个 。 在上面的场景中，为了更 加公平，可以把 **pullBatchSize** 设置成

   1。

3. 强制优先级

   TypeA、 TypeB、 TypeC 三类消息 。 TypeA 处于第一优先级，要确保只要有TypeA消息，必须优

   先处理; TypeB处于第二优先 级; TypeC 处于第三优先级 。 对这种要求，或者逻辑更复杂的要求，就要

   用 户自己编码实现优先级控制，如果上述的 三 类消息在一个 Topic 里，可以使 用 PullConsumer，自

   主控制 MessageQueue 的遍历，以及消息的读取；如果上述三类消息在三个 Topic下，需要启动三个

   Consumer， 实现逻辑控制三个 Consumer 的消费 。

#### 3.3 底层网络通信-Netty高性能之道

​		RocketMQ底层通信的实现是在Remoting模块里，因为借助了Netty而没有重复造轮子，RocketMQ的通信部

分没有很多的代码，就是用Netty实现了一个自定义协议的客户端/服务器程序：

​		RocketMQ消息队列集群主要包括NameServer、Broker(Master/Slave)、Producer、Consumer4个角色，

基本通讯流程如下：

1. Broker启动后需要完成一次将自己注册至NameServer的操作；随后每隔30s时间定时向NameServer上报Topic路由信息。

2.  消息生产者Producer作为客户端发送消息时候，需要根据消息的Topic从本地缓存的TopicPublishInfoTable获取路由信息。如果没有则更新路由信息会从NameServer上重新拉取，同时Producer会默认每隔30s向NameServer拉取一次路由信息。

3. 消息生产者Producer根据2）中获取的路由信息选择一个队列（MessageQueue）进行消息发送；Broker作为消息的接收者接收消息并落盘存储。

4. 消息消费者Consumer根据2）中获取的路由信息，并再完成客户端的负载均衡后，选择其中的某一个或者某几个消息队列来拉取消息并进行消费。

   从上面1）~3）中可以看出在消息生产者, Broker和NameServer之间都会发生通信（这里只说了MQ的部分通

信），因此如何设计一个良好的网络通信模块在MQ中至关重要，它将决定RocketMQ集群整体的消息传输能力与

最终的性能。

​		rocketmq-remoting 模块是 RocketMQ消息队列中负责网络通信的模块，它几乎被其他所有需要网络通信的

模块（诸如rocketmq-client、rocketmq-broker、rocketmq-namesrv）所依赖和引用。为了实现客户端与服务器

之间高效的数据请求与接收，RocketMQ消息队列自定义了通信协议并在Netty的基础之上扩展了通信模块。

​		RocketMQ中惯用的套路：

​		请求报文和响应都使用RemotingCommand，然后在Processor处理器中根据RequestCode请求码来匹配对

应的处理方法。

​		处理器通常继承至NettyRequestProcessor，使用前需要先注册才行，注册方式

remotingServer.registerDefaultProcessor

#####  3.3.1 Remoting通信类结构

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_16-00-33.png)

#####  3.3.2 协议设计与编解码

​		在Client和Server之间完成一次消息发送时，需要对发送的消息进行一个协议约定，因此就有必要

自定义RocketMQ的消息协议。同时，为了高效地在网络中传输消息和对收到的消息读取，就需要对消

息进行编解码。在RocketMQ中，RemotingCommand这个类在消息传输过程中对所有数据内容的封

装，不但包含了所有的数据结构，还包含了编码解码操作。

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_16-07-21.png)

可见传输内容主要可以分为以下4部分：

(1) 消息长度：总长度，四个字节存储，占用一个int类型；

(2) 序列化类型&消息头长度：同样占用一个int类型，第一个字节表示序列化类型，后面三个字节

表示消息头长度；

(3) 消息头数据：经过序列化后的消息头数据；

(4) 消息主体数据：消息主体的二进制字节数据内容；

#####  3.3.3 消息的通信方式和流程

​		在RocketMQ消息队列中支持通信的方式主要有同步(sync)、异步(async)、单向(oneway) 三种。其中“单向”通

信模式相对简单，一般用在发送心跳包场景下，无需关注其Response。这里，主要介绍RocketMQ的异步通信流

程。

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_17-50-14.png)

#####  3.3.4 Reactor 主从多线程模型

​		RocketMQ的RPC通信采用Netty组件作为底层通信库，同样也遵循了Reactor多线程模型，同时又在这之上做

了一些扩展和优化。

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_17-53-04.png)

​		上面的框图中可以大致了解RocketMQ中NettyRemotingServer的Reactor 多线程模型。一个 Reactor 主线程

（eventLoopGroupBoss，即为上面的1）负责监听 TCP网络连接请求，建立好连接，创建SocketChannel，并注

册到selector上。

​		RocketMQ的源码中会自动根据OS的类型选择NIO和Epoll，也可以通过参数配置）,然后监听真正的网络数据。

​		拿到网络数据后，再丢给Worker线程池（eventLoopGroupSelector，即为上面的“N”，源码中默认设置为

3），在真正执行业务逻辑之前需要进行SSL验证、编解码、空闲检查、网络连接管理，这些工作交给

defaultEventExecutorGroup（即为上面的“M1”，源码中默认设置为8）去做。

​		处理业务操作放在业务线程池中执行，根据 RomotingCommand 的业务请求码code去processorTable这个

本地缓存变量中找到对应的 processor，然后封装成task任务后，提交给对应的业务processor处理线程池来执行

（sendMessageExecutor，以发送消息为例，即为上面的 “M2”）。

​		从入口到业务逻辑的几个步骤中线程池一直再增加，这跟每一步逻辑复杂性相关，越复杂，需要的并发通道越宽。

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_17-56-53.png)

####  3.4 客户端配置

​		相对于RocketMQ的Broker集群，生产者和消费者都是客户端。

​		本节主要描述生产者和消费者公共的行为配置。

​		DefaultMQProducer、TransactionMQProducer、DefaultMQPushConsumer、DefaultMQPullConsumer

都继承于ClientConfig类，ClientConfig为客户端的公共配置类。

​		客户端的配置都是get、set形式，每个参数都可以用spring来配置，也可以在代码中配置。

​		例如namesrvAddr这个参数可以这样配置，producer.setNamesrvAddr("192.168.0.1:9876")，其他参数同

理。

#####  3.4.1 客户端寻址方式

​		RocketMQ可以令客户端找到Name Server, 然后通过Name Server再找到Broker。如下所示有多种配置方

式，优先级由高到低，高优先级会覆盖低优先级。

######  代码指定

​		代码中指定Name Server地址，多个namesrv地址之间用**分号**分割

​		producer.setNamesrvAddr("192.168.0.1:9876;192.168.0.2:9876");

​		consumer.setNamesrvAddr("192.168.0.1:9876;192.168.0.2:9876");

######  启动参数指定

​		-Drocketmq.namesrv.addr=192.168.0.1:9876;192.168.0.2:9876

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-49-30.png)

```java
package com.lagou.rocket.demo.producer; 
import org.apache.rocketmq.client.exception.MQBrokerException; 
import org.apache.rocketmq.client.exception.MQClientException; 
import org.apache.rocketmq.client.producer.DefaultMQProducer; 
import org.apache.rocketmq.client.producer.SendResult; 
import org.apache.rocketmq.common.message.Message; 
import org.apache.rocketmq.remoting.exception.RemotingException; 
public class MyProducer { 
    public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException, MQBrokerException {
        DefaultMQProducer producer = new DefaultMQProducer("producer_grp_17_02"); 
        // 不使用代码指定，在启动参数中指定 
        // producer.setNamesrvAddr("node1:9876"); 
        producer.start(); 
        Message message = new Message("tp_demo_17", "hello lagou".getBytes()); 
        SendResult sendResult = producer.send(message);
        System.out.println(sendResult.getSendStatus());
        System.out.println(sendResult.getMsgId()); 
        System.out.println(sendResult.getOffsetMsgId()); 
        producer.shutdown(); 
    } 
}
```

######  环境变量指定

LINUX:

```shell
export NAMESRV_ADDR=192.168.0.1:9876;192.168.0.2:9876
```

WINDOWS:

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-52-43.png)

######  HTTP静态服务器寻址（默认）

​		该静态地址，客户端第一次会10s后调用，然后每个2分钟调用一次。

​		客户端启动后，会定时访问一个静态HTTP服务器，地址如下：http://jmenv.tbsite.net:8080/rocketmq/nsaddr，这个URL的返回内容如下：

​		192.168.0.1:9876;192.168.0.2:9876

​		源码：org.apache.rocketmq.common.MixAll.java中：

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-54-15.png)

​		开发一个服务，让客户端来访问

​		![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-55-57.png)

​		修改/etc/hosts文件：

```shell
127.0.0.1 jmenv.tbsite.net
```

​		在不设置nameserver地址时，依然可以访问，发送消息。

​		推荐使用HTTP静态服务器寻址方式，好处是客户端部署简单，且Name Server集群可以热升级。因为只需要

修改域名解析，客户端不需要重启。

#####  3.4.2 客户端公共配置

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-58-07.png)

#####  3.4.3 Producer配置

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_22-59-12.png)

#####  3.4.4 Consumer配置

######  PushConsumer配置

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_23-01-23.png)

######  PullConsumer配置

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_23-02-23.png)

#####  3.4.5 Message数据结构

![](D:\BaiduNetdiskWorkspace\知识库\图片\RocketMQ\Snipaste_2021-07-03_23-04-00.png)

### 四、 RocketMQ环境搭建

####  4.1 软件准备

RocketMQ最新版本：4.5.1

[下载地址](https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.5.1/rocketmq-all-4.5.1-bin-release.zip)

####  4.2 环境要求

- JDK 11.0.5

- Linux64位系统(CentOS Linux release 7.7.1908)

- 源码安装需要安装Maven 3.2.x

- 4G+ free

####  4.3 安装及启动

#####  下载RocketMQ

```shell
#下载 
wget https://archive.apache.org/dist/rocketmq/4.5.1/rocketmq-all- 4.5.1-bin-release.zip
```

#####  修改脚本

- bin/runserver.sh

  ```shell
  vim bin/runserver.sh 
  删除UseCMSCompactAtFullCollection UseParNewGC UseConcMarkSweepGC 
  修改内存： 
  JAVA_OPT="${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m - XX:MetaspaceSize=64mm -XX:MaxMetaspaceSize=160mm" 
  -Xloggc修改为-Xlog:gc
  ```

  ```shell
  #!/bin/sh 
  # Licensed to the Apache Software Foundation (ASF) under one or more 
  # contributor license agreements. See the NOTICE file distributed with 
  # this work for additional information regarding copyright ownership. 
  # The ASF licenses this file to You under the Apache License, Version 2.0 
  # (the "License"); you may not use this file except in compliance with 
  # the License. You may obtain a copy of the License at 
  #
  # http://www.apache.org/licenses/LICENSE-2.0 
  #
  # Unless required by applicable law or agreed to in writing, software 
  # distributed under the License is distributed on an "AS IS" BASIS, 
  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
  # See the License for the specific language governing permissions and 
  # limitations under the License. #========================================================================== ================= 
  # Java Environment Setting
  #===========================================================================================
  error_exit () 
  {
  echo "ERROR: $1 !!" 
  exit 1
  }
  [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=$HOME/jdk/java 
  [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java 
  [ ! -e "$JAVA_HOME/bin/java" ] && error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!" 
  
  export JAVA_HOME 
  export JAVA="$JAVA_HOME/bin/java" 
  export BASE_DIR=$(dirname $0)/.. 
  export CLASSPATH=.:${BASE_DIR}/conf:${JAVA_HOME}/jre/lib/ext:${BASE_DIR}/lib/* #========================================================================== ================= # JVM Configuration #========================================================================== ================= 
  JAVA_OPT="${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m - XX:MetaspaceSize=64m -XX:MaxMetaspaceSize=160m" 
  JAVA_OPT="${JAVA_OPT} -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+CMSClassUnloadingEnabled -XX:SurvivorRatio=8" 
  JAVA_OPT="${JAVA_OPT} -verbose:gc -Xlog:gc:/dev/shm/rmq_srv_gc.log - XX:+PrintGCDetails" JAVA_OPT="${JAVA_OPT} -XX:-OmitStackTraceInFastThrow" 
  JAVA_OPT="${JAVA_OPT} -XX:-UseLargePages" 
  # JAVA_OPT="${JAVA_OPT} - Djava.ext.dirs=${JAVA_HOME}/jre/lib/ext:${BASE_DIR}/lib" #JAVA_OPT="${JAVA_OPT} -Xdebug - Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n" 
  JAVA_OPT="${JAVA_OPT} ${JAVA_OPT_EXT}" 
  JAVA_OPT="${JAVA_OPT} -cp ${CLASSPATH}" 
  
  $JAVA ${JAVA_OPT} $@
  ```

- bin/runbroker.sh

  ```shell
  vim bin/runbroker.sh 
  删除： 
  PrintGCDateStamps 
  PrintGCApplicationStoppedTime 
  PrintAdaptiveSizePolicy 
  UseGCLogFileRotation 
  NumberOfGCLogFiles=5 
  GCLogFileSize=30m
  ```

  ```shell
  #!/bin/sh 
  # Licensed to the Apache Software Foundation (ASF) under one or more 
  # contributor license agreements. See the NOTICE file distributed with 
  # this work for additional information regarding copyright ownership. 
  # The ASF licenses this file to You under the Apache License, Version 2.0 123456
  # (the "License"); you may not use this file except in compliance with 
  # the License. You may obtain a copy of the License at 
  #
  # http://www.apache.org/licenses/LICENSE-2.0 
  #
  # Unless required by applicable law or agreed to in writing, software 
  # distributed under the License is distributed on an "AS IS" BASIS, 
  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
  # See the License for the specific language governing permissions and 
  # limitations under the License. #========================================================================== ================= 
  # Java Environment Setting #========================================================================== ================= 
  error_exit () 
  { 
  	echo "ERROR: $1 !!" 
  	exit 1 
  }
  [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=$HOME/jdk/java 
  [ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java 
  [ ! -e "$JAVA_HOME/bin/java" ] && error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!" 
  
  export JAVA_HOME 
  export JAVA="$JAVA_HOME/bin/java" 
  export BASE_DIR=$(dirname $0)/.. 
  export CLASSPATH=.${JAVA_HOME}/jre/lib/ext:${BASE_DIR}/lib/*:${BASE_DIR}/conf:${CL ASSPATH} 
  #========================================================================== ================= 
  # JVM Configuration #========================================================================== ================= 
  JAVA_OPT="${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m" 
  JAVA_OPT="${JAVA_OPT} -XX:+UseG1GC -XX:G1HeapRegionSize=16m - XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 - XX:SoftRefLRUPolicyMSPerMB=0" JAVA_OPT="${JAVA_OPT} -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails" JAVA_OPT="${JAVA_OPT} -XX:-OmitStackTraceInFastThrow" 
  JAVA_OPT="${JAVA_OPT} -XX:+AlwaysPreTouch" 
  JAVA_OPT="${JAVA_OPT} -XX:MaxDirectMemorySize=15g" 
  JAVA_OPT="${JAVA_OPT} -XX:-UseLargePages -XX:-UseBiasedLocking" 
  #JAVA_OPT="${JAVA_OPT} -Xdebug -Xrunjdwp:transport=dt_socket,address=9555,server=y,suspend=n" 
  JAVA_OPT="${JAVA_OPT} ${JAVA_OPT_EXT}" 
  JAVA_OPT="${JAVA_OPT} -cp ${CLASSPATH}" 
  
  numactl --interleave=all pwd > /dev/null 2>&1 
  if [ $? -eq 0 ] 
  then
  	if [ -z "$RMQ_NUMA_NODE" ] ; then
  		numactl --interleave=all $JAVA ${JAVA_OPT} $@ 
  	else
  		numactl --cpunodebind=$RMQ_NUMA_NODE --membind=$RMQ_NUMA_NODE $JAVA ${JAVA_OPT}$@ 
  	fi 
  else
  	$JAVA ${JAVA_OPT} --add-exports=java.base/jdk.internal.ref=ALL-UNNAMED $@
  fi
  ```

- bin/tools.sh

```shell
#!/bin/sh 
# Licensed to the Apache Software Foundation (ASF) under one or more 
# contributor license agreements. See the NOTICE file distributed with 
# this work for additional information regarding copyright ownership. 
# The ASF licenses this file to You under the Apache License, Version 2.0 
# (the "License"); you may not use this file except in compliance with 
# the License. You may obtain a copy of the License at 
#
# http://www.apache.org/licenses/LICENSE-2.0 
#
# Unless required by applicable law or agreed to in writing, software 
# distributed under the License is distributed on an "AS IS" BASIS, 
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
# See the License for the specific language governing permissions and 
# limitations under the License. #========================================================================== ================= 
# Java Environment Setting #========================================================================== ================= 
error_exit () 
{ 
	echo "ERROR: $1 !!" exit 1 
}
[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=$HOME/jdk/java 
[ ! -e "$JAVA_HOME/bin/java" ] && JAVA_HOME=/usr/java
[ ! -e "$JAVA_HOME/bin/java" ] && error_exit "Please set the JAVA_HOME variable in your environment, We need java(x64)!" 

export JAVA_HOME export JAVA="$JAVA_HOME/bin/java" 
export BASE_DIR=$(dirname $0)/.. 
# export CLASSPATH=.:${BASE_DIR}/conf:${CLASSPATH} 
export CLASSPATH=.${JAVA_HOME}/jre/lib/ext:${BASE_DIR}/lib/*:${BASE_DIR}/conf:${CL ASSPATH} #========================================================================== ================= 
# JVM Configuration #========================================================================== ================= 
JAVA_OPT="${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn256m -XX:PermSize=128m -XX:MaxPermSize=128m" 
# JAVA_OPT="${JAVA_OPT} - Djava.ext.dirs=${BASE_DIR}/lib:${JAVA_HOME}/jre/lib/ext" 
JAVA_OPT="${JAVA_OPT} -cp ${CLASSPATH}" 

$JAVA ${JAVA_OPT} $@ 
```

#####  启动NameServer

```shell
# 1.启动
NameServer mqnamesrv 
# 2.查看启动日志
tail -f ~/logs/rocketmqlogs/namesrv.log
```

#####  启动Broker

```shell
# 1.启动
Broker mqbroker -n localhost:9876 
# 2.查看启动日志 
tail -f ~/logs/rocketmqlogs/broker.log 1234
```

#####  RocketMQ环境测试

1. 发送消息

   ```shell
   # 1.设置环境变量
   export NAMESRV_ADDR=localhost:9876
   # 2.使用安装包的Demo发送消息
   sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer
   ```

2. 接收消息

   ```shell
   # 1.设置环境变量
   export NAMESRV_ADDR=localhost:9876
   # 2.接收消息
   sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer
   ```

3. 关闭RocketMQ

   ```shell
   # 1.关闭NameServer
   mqshutdown namesrv
   # 2.关闭Broker
   mqshutdown broker
   ```

   



